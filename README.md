## ğŸŒ¦ï¸ Real-Time Weather Data Pipeline with AWS

This project demonstrates a real-time ETL pipeline using AWS services.
It fetches weather data from a public API, ingests it into AWS, processes it, and makes it queryable with Athena.

## ğŸš€ Architecture Overview

## Pipeline flow:

Producer fetches weather data from WeatherAPI (via REST API).

Lambda ETL transforms & stores JSON into S3 (raw folder).

AWS Glue Crawler scans raw JSON â†’ creates schema in Data Catalog.

Amazon Athena queries structured weather data.

Step Functions orchestrate the end-to-end flow.

CloudWatch & SNS provide monitoring and alerts.


## ğŸ“‚ Project Structure
Weather_API_Real_Time_Project/
â”‚â”€â”€ docs/                           # Documentation + diagrams + screenshots
â”‚   â””â”€â”€ readme_images/              # Screenshots used in README (Athena, S3, Step Functions, etc.)
â”‚
â”‚â”€â”€ glue/                           # AWS Glue configurations
â”‚   â””â”€â”€ crawler_config.md           # Notes on Glue crawler setup (weather-data-crawler)
â”‚
â”‚â”€â”€ lambda/                         # Lambda functions (ETL & processing logic)
â”‚   â””â”€â”€ etl-weather-transform/
â”‚       â”œâ”€â”€ lambda_transform.py     # Lambda code for parsing & cleaning weather data
â”‚       â””â”€â”€ lambda_transform_After...py # Alternate version after removing Kinesis
â”‚
â”‚â”€â”€ producer/                       # Data ingestion scripts
â”‚   â””â”€â”€ weather_api_producer.py     # Python script to fetch Weather API data and push to Kinesis/S3
â”‚
â”‚â”€â”€ step_functions/                 # Workflow orchestration
â”‚   â””â”€â”€ weather_pipeline_workflow.asl.json  # Step Functions definition (Lambda â†’ Glue â†’ Athena â†’ Success)
â”‚
â”‚â”€â”€ .env                            # Environment variables (API key, bucket name, region, etc.)
â”‚â”€â”€ .gitignore                      # Prevents committing secrets like `.env` and unnecessary files
â”‚â”€â”€ requirements.txt                # Python dependencies for producer & local testing
â”‚â”€â”€ README.md                       # Main project documentation (overview, steps, diagrams, usage)

## ğŸ“‘ Why Each File/Folders Exists

docs/ â†’ contains diagrams (like architecture.png) and screenshots (Athena queries, CloudWatch, Step Functions flow) for documentation.

glue/crawler_config.md â†’ explains Glue crawler configuration (weather-data-crawler) that scans S3 and updates schema.

lambda/etl-weather-transform/ â†’ holds Lambda transformation code:

Cleans raw JSON from API/Kinesis.

Saves structured data into S3 (raw/ folder).

Alternate version supports direct Step Functions â†’ Lambda â†’ S3 flow.

producer/weather_api_producer.py â†’ script that calls external Weather API and sends data into Kinesis stream (or S3 directly if Kinesis is disabled).

step_functions/weather_pipeline_workflow.asl.json â†’ AWS Step Functions definition for orchestrating the pipeline (Producer â†’ Lambda â†’ Glue â†’ Athena â†’ Success).

.env â†’ sensitive config like API keys, bucket name, region (excluded from GitHub via .gitignore).

.gitignore â†’ makes sure sensitive/unnecessary files like .env, __pycache__/, .DS_Store arenâ€™t pushed to GitHub.

requirements.txt â†’ dependencies (e.g., boto3, requests, python-dotenv) for local testing and running producer script.

README.md â†’ main guide with step-by-step explanation, architecture diagram (Mermaid), and execution details.

## ğŸ”§ End-to-End Technical Workflow
## 1. Weather Data Ingestion

A Python producer script (weather_api_producer.py) calls the [WeatherAPI REST endpoint].

The script retrieves current weather JSON for a specified location.

Instead of storing locally, data is forwarded to the pipeline for processing.

## 2. AWS Lambda â€“ ETL Transformation

Lambda function (lambda_transform.py) receives the raw JSON event.

Handles two event sources:

Step Functions direct payloads (JSON passed inline).

Kinesis records (legacy, with base64 decoding).

Transformation performed:

Extracts city, country, temperature_c, humidity, condition.

Adds ISO 8601 timestamp (datetime.now(datetime.UTC) â†’ non-deprecated).

Output written as JSON file â†’ Amazon S3 under prefix raw/.

Example: s3://<bucket>/raw/weather-data-YYYYMMDDHHMMSS.json.

## 3. Amazon S3 â€“ Data Lake Storage

Acts as the central landing zone.

Folder structure:

s3://<bucket>/raw/                # Incoming raw JSON data
s3://<bucket>/athena-results/     # Athena query results


Each Lambda execution creates a new JSON file in /raw/.

## 4. AWS Glue â€“ Schema Discovery

Glue Crawler (weather-data-crawler) is configured to scan s3://<bucket>/raw/.

Automatically infers schema of JSON files.

Populates AWS Glue Data Catalog with a table:

Database: weather_db

Table: weather_data_jsonraw

Schema includes nested JSON fields (location, current, etc.).

## 5. Amazon Athena â€“ Interactive SQL

Athena queries run on top of the Glue Data Catalog.

Example query:

SELECT
  data.location.name        AS city,
  data.location.country     AS country,
  data.current.temp_c       AS temperature_c,
  data.current.humidity     AS humidity,
  data.current.condition.text AS condition,
  data.current.last_updated AS last_updated
FROM weather_db.weather_data_jsonraw
LIMIT 10;


Results automatically stored in s3://<bucket>/athena-results/.

## 6. AWS Step Functions â€“ Orchestration

State machine (weather_pipeline_workflow.asl.json) orchestrates the flow:

FetchWeatherData â†’ Invokes Lambda ETL.

RunGlueCrawler â†’ Ensures schema is refreshed.

RunAthenaQuery â†’ Runs a pre-defined query for validation.

SuccessState â†’ Marks workflow complete.

All steps are executed sequentially.

## 7. Monitoring & Alerts

CloudWatch Logs â†’ Captures Lambda, Step Functions, and Athena logs.

CloudWatch Alarms â†’ Configured for:

Lambda error rate â‰¥ threshold.

Step Function execution failures.

SNS Notifications â†’ Sends email alerts when pipeline fails.

## ğŸ”‘ Key Technical Notes

Designed for real-time ETL but supports batch re-runs via Step Functions.

Initial design used Kinesis â†’ Lambda â†’ S3, but simplified to Lambda â†’ S3 (removing Kinesis dependency).

Fully serverless architecture â€” no servers to manage.

Can be extended with EventBridge scheduler to run every X minutes.

## ğŸ“Š Architecture Diagram (Mermaid)
flowchart TD

    A[Weather API Producer<br>(Python Script)] -->|REST API JSON| B[Lambda ETL<br>etl-weather-transform]

    B -->|Transformed JSON| C[S3 Bucket<br>praneeth-weather-data/raw]

    C --> D[Glue Crawler<br>weather-data-crawler]
    D --> E[Glue Data Catalog<br>weather_db.weather_data_jsonraw]

    E --> F[Athena Query<br>SQL over Data Catalog]
    F -->|Results| G[S3 Athena Results<br>/athena-results/]

    subgraph StepFunctions[Step Functions Workflow]
        B
        D
        F
        H[Success State]
    end

    B --> D --> F --> H

ğŸ”§ How to Explain This

Producer (your Python script) calls Weather API.

Lambda ETL normalizes JSON and pushes to S3.

Glue Crawler auto-detects schema and updates Glue Data Catalog.

Athena queries the catalog â†’ results saved back to S3.

Step Functions orchestrates the order: Lambda â†’ Crawler â†’ Athena â†’ Success.
